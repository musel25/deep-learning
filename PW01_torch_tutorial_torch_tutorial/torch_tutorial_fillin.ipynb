{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to Pytorch\n",
        "\n",
        "## `autodiff`\n",
        "\n",
        "### Autodiff for simple gradient descent\n",
        "\n",
        "Load needed libraries\n",
        "\n",
        "$$\n",
        "\\newcommand\\p[1]{{\\left(#1\\right)}}\n",
        "\\newcommand\\code[1]{\\texttt{#1}}\n",
        "$$"
      ],
      "id": "f12afb73-03b3-43bd-8766-90027f0abed8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim"
      ],
      "id": "1e4c833c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is a simple example of how to find the minimum of the function\n",
        "$x\\mapsto\\p{x-3}^2$ using the autodiff functionality of Pytorch.\n",
        "\n",
        "First initialize a tensor `x` and indicate that we want to store a\n",
        "gradient on it."
      ],
      "id": "b926550c-d075-498e-b5cb-61f67afa66e2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.tensor([1.0], requires_grad=True)"
      ],
      "id": "c5bbaa5b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an optimizer on parameters. Here we want to optimize w.r.t.\n",
        "variable `x`:"
      ],
      "id": "36c37bf9-4dcc-4865-9265-8ae5f4544e98"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = optim.SGD([x], lr=0.01)"
      ],
      "id": "96b7550b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a computational graph using parameters (here only `x`) and\n",
        "potentially other tensors.\n",
        "\n",
        "Here we only want to compute $\\p{x-3}^2$ so we define:"
      ],
      "id": "62905914-b52c-4891-9332-dc34b6409164"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = (x - 3) ** 2"
      ],
      "id": "24f0c4e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Back-propagating gradients for `y` down to `x`. Don’t forget to reset\n",
        "gradients before."
      ],
      "id": "74c0d8aa-029d-4081-ad05-dd31486cabe1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer.zero_grad()\n",
        "y.backward()"
      ],
      "id": "9c16abf4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use gradient on `x` to apply a one-step gradient descent."
      ],
      "id": "1eff4d24-c33f-4498-95c3-120deb05b2e4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer.step()\n",
        "x.grad\n",
        "x"
      ],
      "id": "4598fbc9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And last we iterate the whole process"
      ],
      "id": "34b8c4ff-c12c-4c9c-a8cc-e21b72303060"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "it = 0\n",
        "while it < 1000:\n",
        "    loss = (x - 3) ** 2\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if it % 20 == 0:\n",
        "        print(\"Iteration: %d, x: %f, loss: %f\" % (it, x.item(), loss.item()))\n",
        "    it += 1"
      ],
      "id": "beda827c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Differentiate the exponential\n",
        "\n",
        "The exponential function can be approximated using its Taylor expansion:\n",
        "$$\n",
        "\\exp\\p{z}\\approx\\sum_{k=0}^{N}\\frac{z^k}{k!}\n",
        "$$\n",
        "\n",
        "First define `x`, the “parameter” and build a computational graph from\n",
        "it to compute the exponential."
      ],
      "id": "0085019d-350f-4eb0-a729-d6366371ef22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "..."
      ],
      "id": "9203c3a0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the gradient and verify that it is correct"
      ],
      "id": "8846b2e4-efdc-4ade-96f8-8bc0b89f425e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "..."
      ],
      "id": "0b84241b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solving equations with Pytorch\n",
        "\n",
        "Suppose we want to solve the following system of two equations\n",
        "\n",
        "$$\n",
        "e^{-e^{-(x_1 + x_2)}}=x_2 (1 + x_1^2)\n",
        "$$ $$\n",
        "x_1 \\cos(x_2) + x_2 \\sin(x_1)= 1/2\n",
        "$$\n",
        "\n",
        "Find a loss whose optimization leads to a solution of the system of\n",
        "equations above."
      ],
      "id": "634f30de-90dd-420c-bed4-1f3eaa25e68f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define two functions\n",
        "..."
      ],
      "id": "3ddc72ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use Pytorch autodiff to solve the system of equations"
      ],
      "id": "f7ac575a-52e0-472b-bad7-4d06cf22cbb1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "..."
      ],
      "id": "9e1cdd9d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear least squares in Pytorch\n",
        "\n",
        "### Synthetic data\n",
        "\n",
        "We use the following linear model:\n",
        "\n",
        "$$\n",
        "y = \\langle\\beta,x\\rangle+\\varepsilon\n",
        "$$\n",
        "\n",
        "where $x\\in\\mathbb R^p$ and $\\varepsilon\\sim\\mathcal N(0, \\sigma^2)$."
      ],
      "id": "ca905c53-153e-4413-a908-47cd722fe4e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "p = 512\n",
        "N = 50000\n",
        "X = torch.randn(N, p)\n",
        "beta = torch.randn(p, 1) / math.sqrt(p)\n",
        "y = torch.mm(X, beta) + 0.5 * torch.randn(N, 1)"
      ],
      "id": "9d097df7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model implementation\n",
        "\n",
        "Every model in Pytorch is implemented as a class that derives from\n",
        "`nn.Module`. The two main methods to implement are:\n",
        "\n",
        "-   `__init__`: Declare needed building blocks to implement forward pass\n",
        "-   `forward`: Implement the forward pass from the input given as\n",
        "    argument"
      ],
      "id": "aa76ae39-82ee-4106-8861-3ab0ba5c932d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class LinearLeastSquare(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(LinearLeastSquare, self).__init__()\n",
        "\n",
        "        # Declaring neural networks building blocks. Here we only need\n",
        "        # a linear transform.\n",
        "        self.linear = ...\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Implementing forward pass. Return corresponding output for\n",
        "        # this neural network.\n",
        "        return ..."
      ],
      "id": "5e397785"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing dataset"
      ],
      "id": "8de90dc2-f58b-4067-9c15-107c51174985"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Gather data coming from Pytorch tensors using `TensorDataset`\n",
        "dataset = ..."
      ],
      "id": "d771e314"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Define `train_loader` that is an iterable on mini-batches using\n",
        "# `DataLoader`\n",
        "batch_size = ...\n",
        "train_loader = ..."
      ],
      "id": "a624dc49"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss function to use\n",
        "from torch.nn import MSELoss\n",
        "loss_fn = ..."
      ],
      "id": "c052573c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimization algorithm\n",
        "from torch.optim import SGD\n",
        "\n",
        "# Instantiate model with `LinearLeastSquare` with the correct input\n",
        "# size.\n",
        "model = ..."
      ],
      "id": "649d2072"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the stochastic gradient descent algorithm with a learning rate of\n",
        "# 0.01 and a momentum of 0.9.\n",
        "optimizer = ..."
      ],
      "id": "93fdc5e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Learning loop"
      ],
      "id": "c7c5aec7-02e8-4dcf-a290-7d3bbba0ea42"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "    for src, tgt in train_loader:\n",
        "        # Forward pass\n",
        "        ...\n",
        "\n",
        "        # Backpropagation on loss\n",
        "        ...\n",
        "\n",
        "        # Gradient descent step\n",
        "        ...\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    print(f\"Epoch {i}/{epochs}: Last loss: {loss}\")"
      ],
      "id": "a5470990"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.arange(len(losses)) / len(losses) * epochs\n",
        "plt.plot(x, losses)"
      ],
      "id": "5ae28227"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the model what should be the minimum MSE?\n",
        "\n",
        "…\n",
        "\n",
        "### Learning loop with scheduler\n",
        "\n",
        "From convex optimization theory the learning rate should be decreasing\n",
        "toward 0. To have something approaching we use a scheduler that is\n",
        "updating the learning rate every epoch."
      ],
      "id": "d8d8be4b-a17b-4fe7-be27-7890e139cd1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "# Define a scheduler\n",
        "model = ...\n",
        "optimizer = ...\n",
        "scheduler = ..."
      ],
      "id": "aecef687"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement the learning loop with a scheduler\n",
        "..."
      ],
      "id": "889dcd23"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-layer perceptron\n",
        "\n",
        "Implement a multi-layer perceptron described by the following function:\n",
        "$$\n",
        "f\\p{x,\\beta}=W_3\\sigma\\p{W_2\\sigma\\p{W_1 x}}\n",
        "$$ where $\\sigma\\p{x}=\\max\\p{x, 0}$."
      ],
      "id": "0b0fbb97-8a20-4d89-94ec-bd20ba6683d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiLayerPerceptron(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "\n",
        "        # Define hyperparameters of neural network and building blocks\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Implement forward pass\n",
        "        ..."
      ],
      "id": "ba4e751a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Synthetic 2-dimensional spiral dataset"
      ],
      "id": "f74cfab0-383b-41d6-9226-a4e155c1fe3a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_classes = 3\n",
        "n_loops = 2\n",
        "n_samples = 1500\n",
        "\n",
        "def spirals(n_classes=3, n_samples=1500, n_loops=2):\n",
        "    klass = np.random.choice(n_classes, n_samples)\n",
        "    radius = np.random.rand(n_samples)\n",
        "    theta = klass * 2 * math.pi / n_classes + radius * 2 * math.pi * n_loops\n",
        "    radius = radius + 0.05 * np.random.randn(n_samples)\n",
        "    return np.column_stack((radius * np.cos(theta), radius * np.sin(theta))).astype(\"float32\"), klass\n",
        "\n",
        "X_, y_ = spirals(n_samples=n_samples, n_classes=n_classes, n_loops=n_loops)\n",
        "plt.scatter(X_[:, 0], X_[:, 1], c=y_)"
      ],
      "id": "ab6484c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing dataset"
      ],
      "id": "ecf0fbac-6996-4fa8-8d3b-1607c3f10d1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "X = torch.from_numpy(X_)\n",
        "y = torch.from_numpy(y_)\n",
        "dataset = TensorDataset(X, y)\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "id": "247723e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_, y_ = spirals(n_samples=1000, n_classes=n_classes, n_loops=n_loops)\n",
        "X = torch.from_numpy(X_)\n",
        "y = torch.from_numpy(y_)\n",
        "test_set = TensorDataset(X, y)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
      ],
      "id": "c8ec30f9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The learning loop"
      ],
      "id": "ba461864-0e90-48b1-8cd1-9f9dc52849ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "loss_fn = CrossEntropyLoss()\n",
        "model = MultiLayerPerceptron(2, 20, 20, n_classes)\n",
        "optimizer = SGD(model.parameters(), lr=0.05)\n",
        "optimizer = Adam(model.parameters())"
      ],
      "id": "5edce450"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "epochs = 1000\n",
        "losses = []\n",
        "models = []\n",
        "for i in range(epochs):\n",
        "    for src, tgt in train_loader:\n",
        "        ...\n",
        "\n",
        "    # Accuracy on the test set\n",
        "    acc = 0.\n",
        "    for src, tgt in test_loader:\n",
        "        prd = model(src).detach().argmax(dim=1)\n",
        "        acc += sum(prd == tgt).item()\n",
        "\n",
        "    acc /= len(test_set)\n",
        "    if i % 20 == 0:\n",
        "        print(f\"Epoch {i}/{epochs}: Test accuracy: {acc}\")\n",
        "\n",
        "    models.append(copy.deepcopy(model))"
      ],
      "id": "75a96c77"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_image_data(model, colors, xs, ys):\n",
        "    \"\"\"Return color image of size H*W*4.\"\"\"\n",
        "\n",
        "    # Generate points in grid\n",
        "    xx, yy = np.meshgrid(xs, ys)\n",
        "    points = np.column_stack((xx.ravel(), yy.ravel())).astype(\"float32\")\n",
        "    points = torch.from_numpy(points)\n",
        "\n",
        "    # Predict class probability on points\n",
        "    prd = model(points).detach()\n",
        "    prd = torch.nn.functional.softmax(prd, dim=1)\n",
        "\n",
        "    # Build a color image from colors\n",
        "    colors = torch.from_numpy(colors)\n",
        "    img = torch.mm(prd, colors).numpy()\n",
        "    img = img.reshape((ynum, xnum, 4))\n",
        "    img = np.minimum(img, 1)\n",
        "\n",
        "    return img\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Get n_classes colors in RGBa form\n",
        "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
        "colors = prop_cycle.by_key()[\"color\"]\n",
        "import matplotlib as mpl\n",
        "colors = mpl.colors.to_rgba_array(colors)[:n_classes, :4].astype(\"float32\")\n",
        "\n",
        "# Draw scatter plot of test set using colors\n",
        "ax.scatter(X[:, 0], X[:, 1], c=colors[y])\n",
        "xmin, xmax = ax.get_xlim()\n",
        "ymin, ymax = ax.get_ylim()\n",
        "xnum, ynum = (int(i) for i in fig.dpi * fig.get_size_inches())\n",
        "\n",
        "# Create discretization\n",
        "xs = np.linspace(xmin, xmax, xnum)\n",
        "ys = np.linspace(ymin, ymax, ynum)\n",
        "img = get_image_data(model, colors, xs, ys)\n",
        "\n",
        "ax.imshow(img, extent=[xmin, xmax, ymin, ymax], origin=\"lower\", alpha=.7)"
      ],
      "id": "ad033d06"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  }
}